{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Очистка данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем использовать немного видоизменённый для наших целей датасет https://archive.ics.uci.edu/ml/datasets/AutoUniv.\n",
    "\n",
    "В нём присутствуют целочисленные, вещественнозначные и категориальные признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('table.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все нечисловые признаки имеют тип object. Найдем их в нашей таблице."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Your code is here\n",
    "cat_features_mask = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(cat_features_mask[cat_features_mask==True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Заполнение пропусков**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В исходных данных могут быть пропущенные значения. Большинство методов машинного обучения не умеют с ними работать. Для этого мы должны каким-нибудь образом заполнить эти пропуски.\n",
    "\n",
    "Способы заполнения пропусков:\n",
    "\n",
    "* средним значением \n",
    "* медианой\n",
    "* самым часто встречающимся значением\n",
    "* каким-то одним новым значением (иногда пропуск в данных можно воспринимать как еще одно категориальное значение).\n",
    "* можно взять часть данных для обучения, а на другой части данных предсказать пропущенные значения (тогда для решения основной задачи нельзя обучаться на первой части данных)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, есть ли пропуски в наших данных и много ли их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#индексы строк с NAN\n",
    "\n",
    "df_real = df[df.columns[~cat_features_mask]]\n",
    "\n",
    "print np.any(np.isnan(df_real))\n",
    "\n",
    "gaps = pd.isnull(df_real).any(1).nonzero()[0]\n",
    "print gaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Удалим все строки, содержащие пропущенные значения.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Your code is here\n",
    "\n",
    "df_drop_na = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Заполним пропуски в данных с помощью встроенного метода Imputer, используя среднее значение признака.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "mis_replacer = preprocessing.Imputer(strategy=\"mean\")\n",
    "df_no_mis = pd.DataFrame(data=mis_replacer.fit_transform(df_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.any(np.isnan(df_no_mis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на столбец 'att2'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('table.csv')\n",
    "\n",
    "df['att2'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**'att2' - время в минутах, в течение которого в машинах работал специально установленный датчик особого типа. Как заполнить пропуски в 'att2'? (этого датчика может в машине не быть)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Your code is here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Работа с выбросами**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "data = df['att3'].fillna(df['att3'].mean()).values\n",
    "plt.hist(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.median(data), np.percentile(data,5), np.percentile(data,95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print sort(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_no_outliers = sort(data)[1:-1]\n",
    "hist(data_no_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем найти аутлаеры с помощью sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "Xdata = [[elem] for elem in data]\n",
    "\n",
    "#max_samples = length of data and contamination is a fraction of outliers in (0,1) \n",
    "clf = IsolationForest(max_samples=..., contamination=...)\n",
    "\n",
    "#fit and predict Xdata\n",
    "#Your code is here\n",
    "\n",
    "#print outliers\n",
    "#Your code is here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример из sklearn по удалению аутлаеров**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# Example settings\n",
    "n_samples = 200\n",
    "outliers_fraction = 0.25\n",
    "clusters_separation = [0, 1, 2]\n",
    "\n",
    "# define two outlier detection tools to be compared\n",
    "classifiers = {\n",
    "    \"One-Class SVM\": svm.OneClassSVM(nu=0.95 * outliers_fraction + 0.05,\n",
    "                                     kernel=\"rbf\", gamma=0.1),\n",
    "    \"Robust covariance\": EllipticEnvelope(contamination=outliers_fraction),\n",
    "    \"Isolation Forest\": IsolationForest(max_samples=n_samples,\n",
    "                                        contamination=outliers_fraction,\n",
    "                                        random_state=rng)}\n",
    "\n",
    "# Compare given classifiers under given settings\n",
    "xx, yy = np.meshgrid(np.linspace(-7, 7, 100), np.linspace(-7, 7, 100))\n",
    "n_inliers = int((1. - outliers_fraction) * n_samples)\n",
    "n_outliers = int(outliers_fraction * n_samples)\n",
    "ground_truth = np.ones(n_samples, dtype=int)\n",
    "ground_truth[-n_outliers:] = -1\n",
    "\n",
    "# Fit the problem with varying cluster separation\n",
    "for i, offset in enumerate(clusters_separation):\n",
    "    np.random.seed(42)\n",
    "    # Data generation\n",
    "    X1 = 0.3 * np.random.randn(n_inliers // 2, 2) - offset\n",
    "    X2 = 0.3 * np.random.randn(n_inliers // 2, 2) + offset\n",
    "    X = np.r_[X1, X2]\n",
    "    # Add outliers\n",
    "    X = np.r_[X, np.random.uniform(low=-6, high=6, size=(n_outliers, 2))]\n",
    "\n",
    "    # Fit the model\n",
    "    plt.figure(figsize=(9, 7))\n",
    "    for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
    "        # fit the data and tag outliers\n",
    "        if clf_name == \"Local Outlier Factor\":\n",
    "            y_pred = clf.fit_predict(X)\n",
    "            scores_pred = clf.negative_outlier_factor_\n",
    "        else:\n",
    "            clf.fit(X)\n",
    "            scores_pred = clf.decision_function(X)\n",
    "            y_pred = clf.predict(X)\n",
    "        threshold = stats.scoreatpercentile(scores_pred,\n",
    "                                            100 * outliers_fraction)\n",
    "        n_errors = (y_pred != ground_truth).sum()\n",
    "        # plot the levels lines and the points\n",
    "        if clf_name == \"Local Outlier Factor\":\n",
    "            # decision_function is private for LOF\n",
    "            Z = clf._decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "        else:\n",
    "            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        subplot = plt.subplot(2, 2, i + 1)\n",
    "        subplot.contourf(xx, yy, Z, levels=np.linspace(Z.min(), threshold, 7),\n",
    "                         cmap=plt.cm.Blues_r)\n",
    "        a = subplot.contour(xx, yy, Z, levels=[threshold],\n",
    "                            linewidths=2, colors='red')\n",
    "        subplot.contourf(xx, yy, Z, levels=[threshold, Z.max()],\n",
    "                         colors='orange')\n",
    "        b = subplot.scatter(X[:-n_outliers, 0], X[:-n_outliers, 1], c='white',\n",
    "                            s=20, edgecolor='k')\n",
    "        c = subplot.scatter(X[-n_outliers:, 0], X[-n_outliers:, 1], c='black',\n",
    "                            s=20, edgecolor='k')\n",
    "        subplot.axis('tight')\n",
    "        subplot.legend(\n",
    "            [a.collections[0], b, c],\n",
    "            ['learned decision function', 'true inliers', 'true outliers'],\n",
    "            prop=matplotlib.font_manager.FontProperties(size=10),\n",
    "            loc='lower right')\n",
    "        subplot.set_xlabel(\"%d. %s (errors: %d)\" % (i + 1, clf_name, n_errors))\n",
    "        subplot.set_xlim((-7, 7))\n",
    "        subplot.set_ylim((-7, 7))\n",
    "    plt.subplots_adjust(0.04, 0.1, 0.96, 0.94, 0.1, 0.26)\n",
    "    plt.suptitle(\"Outlier detection\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Масштабирование признаков**\n",
    "\n",
    "Для применения в особенности линейных методов машинного обучения масштабирование признаков очень важно. Может быть так, что метод даст совершенно неправильный результат без масштабирования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Масштабирование признаков можно выполнить, например, одним из следующих способов способами:\n",
    " - $x_{new} = \\dfrac{x - \\mu}{\\sigma}$, где $\\mu, \\sigma$ — среднее и стандартное отклонение значения признака по всей выборке (StandardScaler в sklearn)\n",
    " - $x_{new} = \\dfrac{x - x_{min}}{x_{max} - x_{min}}$, где $[x_{min}, x_{max}]$ — минимальный интервал значений признака (MinMaxScaler в sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalizer = preprocessing.StandardScaler()\n",
    "df_real_norm = normalizer.fit_transform(df_no_mis)\n",
    "df_real_norm_pd = pd.DataFrame(data=df_real_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mm_scaler = preprocessing.MinMaxScaler()\n",
    "df_mm_scaled = mm_scaler.fit_transform(df_no_mis)\n",
    "df_mm_scaled_pd = pd.DataFrame(data=df_mm_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разберем пример данных, когда масштабирование признаков сильно влияет на результат работы алгоритмов машинного обучения. Рассмотрим точки, равномерно нанесенные на плоскость (в данном датасете в качестве признаков x и y выступают координаты - долгота и широта точек, все точки территориально находятся в Москве)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('scaler_example.csv')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как выглядят точки из датасета. Точки относятся к двум классам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "Xtrain = X[['lat','lon']].values\n",
    "Ytrain = X['class'].values\n",
    "\n",
    "#Plot points of different classes with different colours on one image\n",
    "\n",
    "figure(figsize=(10,10))\n",
    "#Your code is here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(Xtrain,Ytrain)\n",
    "\n",
    "def plot_decision_line(Xtrain, Ytrain, clf, h):\n",
    "\n",
    "    x_min, x_max = Xtrain[:,0].min()-0.01, Xtrain[:,0].max()+0.01\n",
    "    y_min, y_max = Xtrain[:,1].min()-0.01, Xtrain[:,1].max()+0.01\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.contourf(xx, yy, Z)\n",
    "\n",
    "    Ytrain = np.array(Ytrain)\n",
    "    plt.scatter(Xtrain[Ytrain==1][:,0],Xtrain[Ytrain==1][:,1],color='green')\n",
    "    plt.scatter(Xtrain[Ytrain==0][:,0],Xtrain[Ytrain==0][:,1],color='red')\n",
    "\n",
    "    a = clf.coef_[0][0]\n",
    "    b = clf.coef_[0][1]\n",
    "    c = clf.intercept_\n",
    "\n",
    "    K = -a*1./b\n",
    "    B = -c*1./b\n",
    "\n",
    "    xx0 = np.linspace(x_min, x_max)\n",
    "    yy0 = K * xx0 + B\n",
    "\n",
    "    plt.scatter(xx0,yy0)\n",
    "    plt.show()\n",
    "    \n",
    "plot_decision_line(Xtrain, Ytrain, clf, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Мы видим, что SVM абсолютно не справился с задачей. Попробуем теперь масштабировать данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#apply scaler to data and fit classifier\n",
    "#Your code is here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot new decision line\n",
    "#Your code is here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
